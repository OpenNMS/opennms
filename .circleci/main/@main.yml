version: 2.1

aliases:
  - &setup_dct_env
    name: Setup DCT environment
    command: |
      case "${CIRCLE_BRANCH}" in
        "master-"*)
           MINION_IMAGE_VERSION="$(~/project/.circleci/scripts/pom2version.sh ~/project/pom.xml)"
          ;;
        "release-"*)
           MINION_IMAGE_VERSION="release-candidate"
          ;;
        "foundation-"20[1-2][0-9])
           MINION_IMAGE_VERSION="${CIRCLE_BRANCH}"
          ;;
        "develop")
           MINION_IMAGE_VERSION="bleeding"
          ;;
        *)
          MINION_IMAGE_VERSION="${CIRCLE_BRANCH//\//-}"
          ;;
      esac
      echo "export DOCKER_CONTENT_TRUST=1" >> $BASH_ENV
      echo "export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=\"$DCT_DELEGATE_KEY_PASSPHRASE\"" >> $BASH_ENV
      echo "export MINION_DK_REPO=docker.io/opennms/minion" >> $BASH_ENV
      echo "export MINION_IMAGE_VERSION=\"$MINION_IMAGE_VERSION\"" >> $BASH_ENV
      echo "export MINION_AZ_REPO=opennmspubacr.azurecr.io/opennms/minion" >> $BASH_ENV
      echo "export KEY_FOLDER=~/.docker/trust/private" >> $BASH_ENV
  - &setup_dct_key
    name: Setup DCT key
    command: |
      mkdir -p $KEY_FOLDER
      # the key that is used to sign single-arch images
      echo "$DCT_DELEGATE_KEY" | base64 -d > $KEY_FOLDER/$DCT_DELEGATE_KEY_NAME.key
      # the key that is used by Notary to sign the multi-arch minion image
      echo "$DCT_REPO_MINION_KEY" | base64 -d > $KEY_FOLDER/$DCT_REPO_MINION_KEY_NAME.key
      # Azure - key IDs has to match the original IDs
      echo "$AZURE_DCT_CI_KEY" | base64 -d > $KEY_FOLDER/$AZURE_DCT_CI_KEY_ID.key
      echo "$AZURE_DCT_REPO_MINION_KEY" | base64 -d > $KEY_FOLDER/$AZURE_DCT_REPO_MINION_KEY_ID.key
      chmod 600 $KEY_FOLDER/*
      # setup_dct_env must have been run first because it provide DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE
      # that is required for loading the
      docker trust key load $KEY_FOLDER/$DCT_DELEGATE_KEY_NAME.key

docker_container_config: &docker_container_config
  executor: docker-executor

orbs:
  cloudsmith: cloudsmith/cloudsmith@1.0.3
  continuation: circleci/continuation@0.2.0
  # path-filtering: circleci/path-filtering@0.1.1
  sign-packages: opennms/sign-packages@2.1.3

commands:
  extract-pom-version:
      description: "Extracting Maven POM version"
      steps:
        - run:
            name: Extract Maven POM version
            command: .circleci/scripts/pom2version.sh pom.xml > pom-version-cache.key
  cached-checkout:
      description: "Checkout with caching"
      steps:
        - restore_cache:
            keys:
              - source-v3-{{ .Branch }}-{{ .Revision }}
              - source-v3-{{ .Branch }}-
              - source-v3-
        - checkout
        - run:
            name: git config merge.renameLimit
            command: git config merge.renameLimit 999999
        - run:
            name: git fetch origin
            command: git fetch origin
  save-cached-checkout:
      description: "Cache a checkout"
      steps:
        - save_cache:
            key: source-v3-{{ .Branch }}-{{ .Revision }}
            paths:
              - ".git"
  cached-checkout-for-pushing:
      description: "Configure a cached checkout that can push upstream"
      steps:
        - add_ssh_keys:
            fingerprints:
              - "5e:70:a4:1a:f3:9f:39:ca:2a:d9:b5:9a:6c:2b:c3:66"
        - cached-checkout
        - run:
            name: Create git identity
            command: |
              git config user.email "cicd-system@opennms.com"
              git config user.name "CI/CD System"
  restore-maven-cache:
      description: "Maven: Calculate cache key and restore cache"
      steps:
        - run:
            name: Calculate cache key from pom files
            command: find . -type f -name "pom.xml" | grep -v /target/ | sort -u | xargs cat > maven-dependency-pom-cache.key
        - restore_cache:
            keys:
              - maven-dependencies-v3-{{ checksum "pom-version-cache.key" }}-{{ checksum "maven-dependency-pom-cache.key" }}
              - maven-dependencies-v3-{{ checksum "pom-version-cache.key" }}-
        - run:
            name: Remove old artifacts to keep workspace size down
            command: .circleci/scripts/clean-m2.sh
  update-maven-cache:
      description: "Maven: Refresh local repository from POM files"
      steps:
        - run:
            name: Collect Maven Dependencies
            command: |
              ./compile.pl -t \
                -Dbuild.skip.tarball=true \
                --update-plugins \
                -Daether.connector.resumeDownloads=false \
                -Daether.connector.basic.threads=1 \
                -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
                -Pbuild-bamboo \
                -Prun-expensive-tasks \
                -Psmoke \
                --legacy-local-repository \
                --batch-mode \
                dependency:resolve-plugins \
                de.qaware.maven:go-offline-maven-plugin:resolve-dependencies
  save-maven-cache:
    description: "Maven: Save cache"
    steps:
      - save_cache:
          key: maven-dependencies-v3-{{ checksum "pom-version-cache.key" }}-{{ checksum "maven-dependency-pom-cache.key" }}
          paths:
            - ~/.m2
  restore-nodejs-cache:
      description: "NodeJS: Calculate cache key and restore cache"
      steps:
        - run:
            name: Calculate cache key
            command: find core/web-assets -name package\*.json -o -name bower.json | grep -v /target/ | sort -u | xargs cat > nodejs-dependency-json-cache.key
        - restore_cache:
            keys:
              - nodejs-dependencies-v3-{{ checksum "pom-version-cache.key" }}-{{ checksum "nodejs-dependency-json-cache.key" }}
              - nodejs-dependencies-v3-{{ checksum "pom-version-cache.key" }}-
  save-nodejs-cache:
    description: "NodeJS: Save cache"
    steps:
      - save_cache:
          key: nodejs-dependencies-v3-{{ checksum "pom-version-cache.key" }}-{{ checksum "nodejs-dependency-json-cache.key" }}
          paths:
            - ~/.npm
  restore-sonar-cache:
      description: "Sonar: Restore sonar cache"
      steps:
        - restore_cache:
            keys:
              - sonar-cache-v2-{{ checksum "pom-version-cache.key" }}
  save-sonar-cache:
      description: "Sonar: Save sonar cache"
      steps:
        - save_cache:
            key: sonar-cache-v2-{{ checksum "pom-version-cache.key" }}
            paths:
              - ~/.sonar
  dockerhub-login:
    description: "Connect to DockerHub"
    steps:
      - run:
          name: Login to DockerHub
          command: |
            if [ -n "${DOCKERHUB_LOGIN}" ]; then
              docker login -u ${DOCKERHUB_LOGIN} -p ${DOCKERHUB_PASS}
            else
              echo "WARNING: dockerhub login not found. Assuming this is a PR or other external branch build."
            fi
  acr-login:
    description: "Connect to Azure Container Registry"
    steps:
      - run:
          name: Login to ACR
          command: |
            PUBACR=opennmspubacr.azurecr.io
            if [ -n "${AZURE_SP_PASSWORD}" ]; then
              docker login -u ${AZURE_SP} -p ${AZURE_SP_PASSWORD} ${PUBACR}
            else
              echo "WARNING: Azure credentials not found. Assuming this is a PR or other external branch build."
            fi
  run-smoke-tests:
    description: "Run the smoke tests"
    parameters:
      suite:
        default: core
        type: string
    steps:
      - run:
          name: Enable swap
          command: |
            sudo fallocate -l 8G /swapfile
            sudo chmod 600 /swapfile
            sudo mkswap /swapfile
            sudo swapon /swapfile
            sudo sysctl vm.swappiness=5
            cat /proc/sys/vm/swappiness
      - load-oci:
          key: horizon
      - load-oci:
          key: minion
      - load-oci:
          key: sentinel
      - run:
          name: Monitor JVM processes
          background: true
          command: |
            .circleci/scripts/jvmprocmon-start.sh
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Smoke Tests
          no_output_timeout: 30m
          command: |
            .circleci/scripts/smoke.sh << parameters.suite >>
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/test-results/system-logs
            (dmesg || :) > ~/test-results/system-logs/dmesg 2>&1
            (ps auxf || :) > ~/test-results/system-logs/ps 2>&1
            (free -m || :) > ~/test-results/system-logs/free 2>&1
            (docker stats --no-stream || :) > ~/test-results/system-logs/docker_stats 2>&1
            cp -R /tmp/jvmprocmon ~/test-results/system-logs/ || :
            ls -alh ~/project/smoke-test/ || :
      - run:
          name: Gather test artifacts
          when: always
          command: |
            mkdir -p ~/test-results/junit
            find . -type f -regex ".*/target/surefire-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
            find . -type f -regex ".*/target/failsafe-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
            mkdir -p ~/test-artifacts/recordings
            cp -R ~/project/smoke-test/target/*.flv ~/test-artifacts/recordings || true
            cp -R ~/project/smoke-test/target/screenshots ~/test-artifacts/ || true
            cp -R ~/project/smoke-test/target/logs ~/test-artifacts/ || true
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          when: always
          path: ~/test-results
          destination: test-results
      - store_artifacts:
          when: always
          path: ~/test-artifacts
          destination: test-artifacts
  run-build:
    description: "Run the main build"
    parameters:
      number-vcpu:
        default: 8
        type: integer
      node-memory:
        default: echo "NODE_OPTIONS Not Set"
        type: string
      vaadin-javamaxmem:
        default: 1g
        type: string
    steps:
      - cached-checkout
      - save-cached-checkout
      - extract-pom-version
      - run:
          name: Check for Releasability
          command: |
            export OPENNMS_VERSION="$(.circleci/scripts/pom2version.sh pom.xml)"
            .circleci/scripts/release-lint.sh "${OPENNMS_VERSION}"
      - restore-maven-cache
      - restore-nodejs-cache
      - run:
          name: Compile OpenNMS
          command: |
            export OPENNMS_VERSION="$(.circleci/scripts/pom2version.sh pom.xml)"
            .circleci/scripts/configure-signing.sh
            ./clean.pl
            << parameters.node-memory >>
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            MAVEN_TARGETS="install"
            case "${CIRCLE_BRANCH}" in
              "master-"*|"release-"*|develop|jira/NMS-13820)
                mkdir -p target/artifacts
                MAVEN_TARGETS="$MAVEN_TARGETS javadoc:aggregate"
                ;;
            esac
            ./compile.pl -DskipTests=true -Dbuild.skip.tarball=false \
              -Daether.connector.resumeDownloads=false \
              -Daether.connector.basic.threads=1 \
              -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
              -DvaadinJavaMaxMemory=<< parameters.vaadin-javamaxmem >> \
              -DmaxCpus=<< parameters.number-vcpu >> \
              -Psmoke \
              --batch-mode \
              $MAVEN_TARGETS
            if [ -d target/site/apidocs ]; then
              pushd target/site/apidocs
                tar -czf "../../artifacts/opennms-${OPENNMS_VERSION}-javadoc.tar.gz" *
              popd
            fi
      - update-maven-cache
      - run:
          name: Remove Extra Maven Repository OpenNMS Files
          command: |
            # move these out of the way so they're not stored in the maven pre-cache
            cd ~/.m2/repository/org/opennms
            mkdir /tmp/maven-keep
            mv $(ls -1 | grep -v -E '^(jicmp-api|jicmp6-api|jrrd-api|jrrd2-api|lib|maven)$') /tmp/maven-keep
      - save-maven-cache
      - run:
          name: Restore Extra Maven Repository OpenNMS Files
          command: |
            # now move them back so they end up in the workspace for builds further down the workflow
            mv /tmp/maven-keep/* ~/.m2/repository/org/opennms/
      - save-nodejs-cache
      - store_artifacts:
          path: ~/project/target/artifacts
          destination: artifacts
      - persist_to_workspace:
          root: ~/
          paths:
            - project
            - .m2
  run-integration-tests:
    parameters:
      run-code-coverage:
        default: false
        type: boolean
      rerun-failtest-count:
        default: 0
        type: integer
      failure-option:
        default: -fae
        type: string
      changes-only:
        default: true
        type: boolean
    steps:
      - run:
          name: Monitor JVM processes
          background: true
          command: |
            .circleci/scripts/jvmprocmon-start.sh
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Integration Tests
          no_output_timeout: 15m
          command: |
            export CCI_CODE_COVERAGE=<< parameters.run-code-coverage >>
            export CCI_RERUN_FAILTEST=<< parameters.rerun-failtest-count >>
            export CCI_FAILURE_OPTION=<< parameters.failure-option >>
            export CCI_CHANGES_ONLY=<< parameters.changes-only >>
            .circleci/scripts/itest.sh
      - run:
          name: Gather test results
          when: always
          command: |
            mkdir -p ~/test-results/junit
            find . -type f -regex ".*/target/.*-reports-[0-9]+/.*xml" -exec cp {} ~/test-results/junit/ \;
            find . -type f -regex ".*/target/.*-reports-[0-9]+/.*dump.*" -exec cp {} ~/test-results/junit/ \;
      - run:
          name: Gather tests
          when: always
          command: |
            mkdir -p ~/generated-tests
            cp ./surefire_classname* ~/generated-tests/ || :
            cp ./failsafe_classname* ~/generated-tests/ || :
            cp /tmp/this_node* ~/generated-tests/       || :
      - when:
          condition: << parameters.run-code-coverage >>
          steps:
            - run:
                name: Compress Target Directories (Code Coverage)
                when: always
                command: |
                  .circleci/scripts/codecoverage-save.sh
            - persist_to_workspace:
                root: ~/
                paths:
                  - code-coverage
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/build-results/system-logs
            (dmesg || :) > ~/build-results/system-logs/dmesg 2>&1
            (ps auxf || :) > ~/build-results/system-logs/ps 2>&1
            (free -m || :) > ~/build-results/system-logs/free 2>&1
            (docker stats --no-stream || :) > ~/build-results/system-logs/docker_stats 2>&1
            cp -R /tmp/jvmprocmon ~/build-results/system-logs/ || :
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          when: always
          path: ~/test-results
          destination: test-results
      - store_artifacts:
          when: always
          path: ~/build-results
          destination: build-results
      - store_artifacts:
          when: always
          path: ~/generated-tests
          destination: generated-tests
  cache-workflow-assets:
    parameters:
      cache_prefix:
        description: the cache prefix
        type: string
      source_path:
        description: the source directory to cache
        type: string
    steps:
      - run:
          name: Stowing Assets in << parameters.source_path >> to cache prefix << parameters.cache_prefix >>
          command: |
            TARGET_PATH="/tmp/<< parameters.cache_prefix >>"
            rsync -ar "$(echo "<< parameters.source_path >>" | sed -e 's,/*$,,')/" "${TARGET_PATH}/"
            find "${TARGET_PATH}" -type d -print0 | xargs -0 chmod 775
            find "${TARGET_PATH}" ! -type d -print0 | xargs -0 chmod 664
      - save_cache:
          key: << parameters.cache_prefix >>-v3-{{ .Branch }}-{{ .Revision }}-{{ .Environment.CIRCLE_SHA1 }}
          paths:
            - "/tmp/<< parameters.cache_prefix >>"
  restore-workflow-assets:
    parameters:
      cache_prefix:
        description: the cache prefix
        type: string
      target_path:
        description: the target directory to restore into
        type: string
        default: ""
    steps:
      - restore_cache:
          keys:
            - << parameters.cache_prefix >>-v3-{{ .Branch }}-{{ .Revision }}-{{ .Environment.CIRCLE_SHA1 }}
      - when:
          condition: << parameters.target_path >>
          steps:
            - run:
                name: Restoring assets to << parameters.target_path >> from cached prefix << parameters.cache_prefix >>
                command: |
                  SOURCE_PATH="/tmp/<< parameters.cache_prefix >>"
                  mkdir -p "<< parameters.target_path >>"
                  rsync -ar "${SOURCE_PATH}/" "$(echo "<< parameters.target_path >>" | sed -e 's,/*$,,')/"
  cache-oci:
    parameters:
      key:
        description: the cache key for storing the OCI
        type: string
      path:
        description: the path to the directory containing the OCI
        type: string
    steps:
      - cache-workflow-assets:
          cache_prefix: oci-<< parameters.key >>
          source_path: << parameters.path >>
  load-oci:
    parameters:
      key:
        description: the OCI cache key to restore
        type: string
    steps:
      - restore-workflow-assets:
          cache_prefix: oci-<< parameters.key >>
      - run:
          name: Load Docker Image(s) in oci-<< parameters.key >>
          command: |
            cd "/tmp/oci-<< parameters.key >>"
            if [ "$(ls -1 *.oci | wc -l)" -eq 0 ]; then
              echo "ERROR: No OCI files to load. Something probably went wrong earlier."
              exit 1
            fi
            for FILE in *.oci; do
              echo "Loading ${FILE} into Docker..."
              docker image load -i "$FILE"
            done

workflows:
  weekly-coverage:
    when:
      equal: [ true, << pipeline.parameters.trigger-coverage >> ]
    jobs:
      - build
      - integration-test-with-coverage:
          requires:
            - build
      - code-coverage:
          requires:
            - integration-test-with-coverage
  build-minimal:
    when:
      and:
        - equal: [ false, << pipeline.parameters.trigger-coverage >> ]
        - equal: [ true, << pipeline.parameters.trigger-build >> ]
        - equal: [ true, << pipeline.parameters.minimal >> ]
    jobs:
      - build
      - create-merge-foundation-branch:
          requires:
            - build
          filters:
            branches:
              only: << pipeline.parameters.main_branch >>
      - merge-foundation-branch:
          requires:
            - build
          filters:
            branches:
              only: merge-foundation/<< pipeline.parameters.previous_branch_label >>-to-<< pipeline.parameters.main_branch_label >>
      - create-merge-meridian-branch:
          requires:
            - build
          filters:
            branches:
              only: /^foundation.*/
      - merge-poweredby-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - build
          filters:
            branches:
              only:
                - /^foundation.*/
  docs:
    when:
      and:
        - equal: [ false, << pipeline.parameters.trigger-coverage >> ]
        - equal: [ true,  << pipeline.parameters.trigger-docs >> ]
        - equal: [ false, << pipeline.parameters.minimal >> ]
    jobs:
      - build-docs:
          filters:
            branches:
              ignore:
                - /^from-foundation.*/
  ui:
    when:
      and:
        - equal: [ false, << pipeline.parameters.trigger-coverage >> ]
        - equal: [ true,  << pipeline.parameters.trigger-ui >> ]
        - equal: [ false, << pipeline.parameters.minimal >> ]
    jobs:
      - build-ui:
          filters:
            branches:
              ignore:
                - /^from-foundation.*/
  build-deploy:
    when:
      and:
        - equal: [ false, << pipeline.parameters.trigger-coverage >> ]
        - equal: [ true,  << pipeline.parameters.trigger-build >> ]
        - equal: [ false, << pipeline.parameters.minimal >> ]
    jobs:
      - build:
          filters:
            branches:
              ignore:
                - /^from-foundation.*/
      - tarball-assembly:
          requires:
            - build
      - minion-image-single-arch:
          matrix:
            parameters:
              architecture: [linux/amd64,linux/arm64,linux/arm/v7]
          context:
            - docker-content-trust
            - azure-sp-dct
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - integration-test
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-minimal
            - smoke-test-sentinel
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
      - minion-image-multi-arch:
          context:
            - docker-content-trust
            - azure-sp-dct
          requires:
            - minion-image-single-arch
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
      - horizon-rpm-build:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - minion-rpm-build:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - sentinel-rpm-build:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - integration-test:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - smoke-test-core:
          requires:
            - tarball-assembly
            - horizon-rpm-build
            - minion-rpm-build
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-flaky:
          requires:
            - tarball-assembly
            - horizon-rpm-build
            - minion-rpm-build
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-minion:
          requires:
            - tarball-assembly
            - horizon-rpm-build
            - minion-rpm-build
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-sentinel:
          requires:
            - tarball-assembly
            - horizon-rpm-build
            - tarball-assembly
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-minimal:
          requires:
            - tarball-assembly
            - horizon-rpm-build
            - tarball-assembly
            - sentinel-rpm-build
          filters:
            branches:
              ignore:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^merge-foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - horizon-publish-oci:
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - integration-test
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-minimal
            - smoke-test-sentinel
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^features\/.+/
      - sentinel-publish-oci:
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - integration-test
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-minimal
            - smoke-test-sentinel
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^features\/.+/
      # These don't actually require `integration-test` but we shouldn't bother
      # spending cycles unless everything else passed
      - horizon-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - minion-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - sentinel-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - create-merge-foundation-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - integration-test
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-minimal
            - smoke-test-sentinel
          filters:
            branches:
              only: << pipeline.parameters.main_branch >>
      - merge-foundation-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - tarball-assembly
          filters:
            branches:
              only: merge-foundation/<< pipeline.parameters.previous_branch_label >>-to-<< pipeline.parameters.main_branch_label >>
      - create-merge-meridian-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - integration-test
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-minimal
            - smoke-test-sentinel
          filters:
            branches:
              only: /^foundation.*/
      - merge-poweredby-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-sentinel
            - smoke-test-minimal
            - integration-test
          filters:
            branches:
              only:
                - /^foundation.*/
      - publish-cloudsmith:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - integration-test
            - smoke-test-core
            - smoke-test-flaky
            - smoke-test-minion
            - smoke-test-minimal
            - smoke-test-sentinel
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/

jobs:
  build:
    executor: centos-build-executor
    # Building currently requires the xlarge containers in order for the webpack compilation
    # in the core/web-assets module to complete reliably
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - run-build:
          number-vcpu: 8
  build-ui:
    executor: ui-executor
    steps:
      - checkout
      - run:
          name: Build
          command: |
            cd ui && yarn install && yarn test && yarn build
  build-docs:
    executor: docs-executor
    steps:
      - cached-checkout
      - run:
          name: Validate Xrefs in docs
          command: |
            NODE_PATH="$(npm -g root)" antora --generator @antora/xref-validator antora-playbook-local.yml
      - run:
          name: Build docs with Antora
          command: |
             DOCSEARCH_ENABLED=true DOCSEARCH_ENGINE=lunr NODE_PATH="$(npm -g root)" antora --generator antora-site-generator-lunr --stacktrace generate antora-playbook-local.yml
      - store_artifacts:
          path: ~/project/build/site.zip
          destination: site.zip
  tarball-assembly:
    machine:
      image: ubuntu-2004:202010-01
      docker_layer_caching: true
    resource_class: xlarge
    environment:
      DOCKER_CLI_EXPERIMENTAL: enabled
    parameters:
      number-vcpu:
        default: 4
        type: integer
      vaadin-javamaxmem:
        default: 1g
        type: string
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: multiarch/qemu-user-static
          command: docker run --privileged multiarch/qemu-user-static --reset -p yes
      - run:
          name: Install Docker buildx
          command: |
            sudo wget https://github.com/docker/buildx/releases/download/v0.5.1/buildx-v0.5.1.linux-amd64 -O /usr/local/bin/docker-buildx
            sudo chmod a+x /usr/local/bin/docker-buildx
            sudo systemctl restart docker
      - dockerhub-login
      - acr-login
      - run:
          name: Assemble tarballs and related artifacts
          command: |
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            # general assembly
            date
            ./compile.pl -DskipTests=true -Dbuild.skip.tarball=false \
              -Daether.connector.resumeDownloads=false \
              -Daether.connector.basic.threads=1 \
              -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
              -DvaadinJavaMaxMemory=<< parameters.vaadin-javamaxmem >> \
              -DmaxCpus=<< parameters.number-vcpu >> \
              -Pbuild-bamboo \
              -Prun-expensive-tasks \
              -Dopennms.home=/opt/opennms \
              install --batch-mode
      - run:
          name: Build Minion OCI
          command: |
            cd opennms-container/minion

            # Create always a downloadable single OCI artifact for AMD architecture.
            # This image is used in our integration test suite which relies on the tag "minion:latest".
            make VERSION="$(../pom2version.py ../../pom.xml)" \
                 DOCKER_TAG="minion:latest" \
                 BUILD_NUMBER="${CIRCLE_BUILD_NUM}" \
                 BUILD_URL="${CIRCLE_BUILD_URL}" \
                 BUILD_BRANCH="${CIRCLE_BRANCH}"
      - run:
          name: Collect Artifacts
          command: |
            mkdir -p target/{artifacts,config-schema,tarballs}
            OPENNMS_VERSION="$(.circleci/scripts/pom2version.sh pom.xml)"
            find ./target -name "*.tar.gz" -type f -not -iname '*source*' -exec cp {} "./target/tarballs/opennms-${OPENNMS_VERSION}.tar.gz" \;
            find ./opennms-assemblies/minion/target -name "*.tar.gz" -type f -not -iname '*source*' -exec cp {} "./target/tarballs/minion-${OPENNMS_VERSION}.tar.gz" \;
            find ./opennms-assemblies/sentinel/target -name "*.tar.gz" -type f -not -iname '*source*' -exec cp {} "./target/tarballs/sentinel-${OPENNMS_VERSION}.tar.gz" \;
            cp ./opennms-assemblies/xsds/target/*-xsds.tar.gz "./target/artifacts/opennms-${OPENNMS_VERSION}-xsds.tar.gz"
            cp target/*-source.tar.gz ./target/artifacts/
            cp opennms-container/minion/minion-config-schema.yml "./target/config-schema/"
      - store_artifacts:
          when: always
          path: ~/project/target/artifacts
          destination: artifacts
      - store_artifacts:
          when: always
          path: ~/project/target/config-schema
          destination: config-schema
      - store_artifacts:
          when: always
          path: ~/project/target/tarballs
          destination: tarballs
      - store_artifacts:
          path: ~/project/opennms-container/minion/images/minion.oci
          destination: minion.oci
      - cache-workflow-assets:
          cache_prefix: minion-config-schema
          source_path: target/config-schema/
      - cache-oci:
          key: minion
          path: opennms-container/minion/images/
      - persist_to_workspace:
          root: ~/
          paths:
            - project/opennms-assemblies/minion/target/org.opennms.assemblies.minion-*-minion.tar.gz

  minion-image-single-arch:
    parameters:
      architecture:
        type: string
    machine:
      image: ubuntu-2004:202010-01
    environment:
      DOCKER_CLI_EXPERIMENTAL: enabled
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: multiarch/qemu-user-static
          command: docker run --privileged multiarch/qemu-user-static --reset -p yes
      - run:
          name: Install Docker buildx
          command: |
            sudo wget https://github.com/docker/buildx/releases/download/v0.5.1/buildx-v0.5.1.linux-amd64 -O /usr/local/bin/docker-buildx
            sudo chmod a+x /usr/local/bin/docker-buildx
            sudo systemctl restart docker
      - dockerhub-login
      - acr-login
      - run: *setup_dct_env
      - run: *setup_dct_key
      - run:
          name: Single-arch build & push
          command: |
            cd opennms-container/minion
            ARCH="$(printf "<< parameters.architecture >>" | tr / -)"
            TAG="${MINION_IMAGE_VERSION}-${ARCH}"
            make DOCKER_ARCH="<< parameters.architecture >>" \
                 DOCKER_FLAGS=--load \
                 VERSION="${TAG}" \
                 BUILD_NUMBER="${CIRCLE_BUILD_NUM}" \
                 BUILD_URL="${CIRCLE_BUILD_URL}" \
                 BUILD_BRANCH="${CIRCLE_BRANCH}"
            docker push ${MINION_DK_REPO}:${TAG}
            echo "pushed to DK"
            docker tag ${MINION_DK_REPO}:${TAG} ${MINION_AZ_REPO}:${TAG}
            export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=${AZURE_DCT_CI_PASSPHRASE}
            docker trust key load $KEY_FOLDER/$AZURE_DCT_CI_KEY_ID.key
            docker push ${MINION_AZ_REPO}:${TAG}
            echo "pushed to AZ"

  minion-image-multi-arch:
    machine:
      image: ubuntu-2004:202010-01
    environment:
      DOCKER_CLI_EXPERIMENTAL: enabled
    steps:
      - attach_workspace:
          at: ~/
      - dockerhub-login
      - acr-login
      - run: *setup_dct_env
      - run: *setup_dct_key
      - run:
          name: Install notary
          command: |
            sudo wget https://github.com/theupdateframework/notary/releases/download/v0.6.1/notary-Linux-amd64 -O /usr/local/bin/notary
            sudo chmod a+x /usr/local/bin/notary
      - run:
          name: Create & push multi-arch manifest
          command: |
            create_and_push_manifest(){
              IMAGE_REF="${1}:${MINION_IMAGE_VERSION}"
              docker manifest create ${IMAGE_REF} \
                ${IMAGE_REF}-linux-amd64 \
                ${IMAGE_REF}-linux-arm64 \
                ${IMAGE_REF}-linux-arm-v7 \
                --amend
              SHA_256="$(docker manifest push "${IMAGE_REF}" --purge | cut -d ':' -f 2)"
              echo "Manifest SHA-256: ${SHA_256}"
              echo "Image-Ref: ${IMAGE_REF}"
              MANIFEST_FROM_REG="$(docker manifest inspect "${IMAGE_REF}" -v)";
              BYTES_SIZE="$(printf "${MANIFEST_FROM_REG}" | jq -r '.[].Descriptor.size' | uniq)";
              echo "Manifest-inspect BYTES: ${BYTES_SIZE}";
              echo "Manifest contents:\n";
              printf "${MANIFEST_FROM_REG}" | jq -r '.[].Descriptor | "Architecture: " + .platform.architecture + .platform.variant + ", digest: " + .digest';
              export SHA_256_${2}="${SHA_256}"
              export BYTES_SIZE_${2}="${BYTES_SIZE}"
            }

            # Docker multi-arch manifest
            create_and_push_manifest $MINION_DK_REPO DK

            # Azure multi-arch manifest
            create_and_push_manifest $MINION_AZ_REPO AZ

            # Notary sign on Docker
            export NOTARY_AUTH="$(printf "${DOCKERHUB_LOGIN}:${DOCKERHUB_PASS}" | base64 -w0)"
            echo "Sign ${SHA_256_DK} with Docker notary"
            # when the multi-arch image is signed by the delegate key then docker pull reports "No valid trust data..."
            # -> the following lines can not be used:
            #
            # export NOTARY_DELEGATION_PASSPHRASE="${DCT_DELEGATE_KEY_PASSPHRASE}"
            # notary -d ~/.docker/trust/ -s https://notary.docker.io addhash "${MINION_DK_REPO}" "${MINION_IMAGE_VERSION}" 946 --sha256 "${SHA_256_DK}" --roles targets/opennms-circle-delegate --publish --verbose
            #
            # -> use the targets key of the minion repository to sign the multi-arch image instead
            export NOTARY_TARGETS_PASSPHRASE="${DCT_REPO_MINION_KEY_PASSPHRASE}"
            notary -d ~/.docker/trust/ -s https://notary.docker.io addhash "${MINION_DK_REPO}" "${MINION_IMAGE_VERSION}" "${BYTES_SIZE_DK}" --sha256 "${SHA_256_DK}" --publish --verbose
            echo "Dockerhub Done!"
            # notary -d ~/.docker/trust/ -s https://notary.docker.io list "${MINION_DK_REPO}"

            # Notary sign on Azure
            NOTARY_AZ_SERVER="https://opennmspubacr.azurecr.io"
            export NOTARY_AUTH="$(printf "${AZURE_SP}:${AZURE_SP_PASSWORD}" | base64 -w0)"

            # publishing a new manifests requires targets key
            export NOTARY_TARGETS_PASSPHRASE="${AZURE_DCT_REPO_MINION_KEY_PASSPHRASE}"
            echo "Sign ${SHA_256_AZ} with Azure notary"
            notary -d ~/.docker/trust/ -s "${NOTARY_AZ_SERVER}" addhash "${MINION_AZ_REPO}" "${MINION_IMAGE_VERSION}" "${BYTES_SIZE_AZ}" --sha256 "${SHA_256_AZ}" --publish --verbose
            echo "ACR Done!"
            # notary -d ~/.docker/trust/ -s "${NOTARY_AZ_SERVER}" list "${MINION_AZ_REPO}"

  horizon-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/makerpm.sh tools/packages/opennms/opennms.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Fetch RPM artifacts and build Horizon container image
          command: |
            cd opennms-container/horizon
            ./build_container_image.sh
      - store_artifacts:
          path: ~/project/opennms-container/horizon/images/container.oci
          destination: horizon.oci
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - cache-workflow-assets:
          cache_prefix: rpm-horizon
          source_path: target/rpm/RPMS/noarch
      - cache-oci:
          key: horizon
          path: opennms-container/horizon/images/
  minion-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    # Will need to increase resource class if horizon-rpm-build is under 15 min
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/makerpm.sh tools/packages/minion/minion.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - cache-workflow-assets:
          cache_prefix: rpm-minion
          source_path: target/rpm/RPMS/noarch
  sentinel-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    # Will need to increase resource class if horizon-rpm-build is under 19 min
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/makerpm.sh tools/packages/sentinel/sentinel.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Fetch RPM artifacts and build Sentinel container image
          command: |
            cd opennms-container/sentinel
            ./build_container_image.sh
      - store_artifacts:
          path: ~/project/opennms-container/sentinel/images/container.oci
          destination: sentinel.oci
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - cache-workflow-assets:
          cache_prefix: rpm-sentinel
          source_path: target/rpm/RPMS/noarch
      - cache-oci:
          key: sentinel
          path: opennms-container/sentinel/images/
  horizon-deb-build:
    executor: debian-build-executor
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=2
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/makedeb.sh opennms
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/build-results/system-logs
            (dmesg || :) > ~/build-results/system-logs/dmesg 2>&1
            (ps auxf || :) > ~/build-results/system-logs/ps 2>&1
            (free -m || :) > ~/build-results/system-logs/free 2>&1
            (docker stats --no-stream || :) > ~/build-results/system-logs/docker_stats 2>&1
            cp -R /tmp/jvmprocmon ~/build-results/system-logs/ || :
      - store_artifacts:
          when: always
          path: ~/build-results
          destination: build-results
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - cache-workflow-assets:
          cache_prefix: deb-horizon
          source_path: target/debs
  minion-deb-build:
    executor: debian-build-executor
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/makedeb.sh minion
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - cache-workflow-assets:
          cache_prefix: deb-minion
          source_path: target/debs
  sentinel-deb-build:
    executor: debian-build-executor
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/makedeb.sh sentinel
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - cache-workflow-assets:
          cache_prefix: deb-sentinel
          source_path: target/debs
  horizon-publish-oci:
    executor: centos-build-executor
    steps:
      - cached-checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - dockerhub-login
      - acr-login
      - load-oci:
          key: horizon
      - run:
          name: tag horizon Docker image and publish to registry
          command: |
            cd opennms-container/horizon
            ./tag.sh
            ./publish.sh
  sentinel-publish-oci:
    executor: centos-build-executor
    steps:
      - cached-checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - dockerhub-login
      - acr-login
      - load-oci:
          key: sentinel
      - run:
          name: tag sentinel Docker image and publish to registry
          command: |
            cd opennms-container/sentinel
            ./tag.sh
            ./publish.sh
  integration-test:
    executor: integration-test-executor
    parallelism: 8
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - run-integration-tests:
          rerun-failtest-count: 1
  integration-test-with-coverage:
    executor: integration-test-executor
    parallelism: 10
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - run-integration-tests:
          run-code-coverage: true
          rerun-failtest-count: 0
          failure-option: -fn
          changes-only: false
  code-coverage:
    executor: centos-build-executor
    resource_class: medium
    steps:
      - attach_workspace:
          at: ~/
      - extract-pom-version
      - restore-sonar-cache
      - run:
          name: Restore Target Directories (Code Coverage)
          when: always
          command: |
            .circleci/scripts/codecoverage-restore.sh
      - run:
          name: Run SonarQube Code Analysis
          when: always
          command: |
            export MAVEN_OPTS="-Xmx8g -XX:ReservedCodeCacheSize=1g -XX:+TieredCompilation"
            .circleci/scripts/sonar.sh
      - save-sonar-cache
  smoke-test-core:
    executor: smoke-test-executor
    parallelism: 8
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: core
  smoke-test-flaky:
    executor: smoke-test-executor
    parallelism: 5
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: flaky
  smoke-test-minion:
    executor: smoke-test-executor
    parallelism: 4
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: minion
  smoke-test-sentinel:
    executor: smoke-test-executor
    parallelism: 5
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: sentinel
  smoke-test-minimal:
    executor: smoke-test-executor
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: minimal
  create-merge-foundation-branch:
    <<: *docker_container_config
    steps:
      - run:
          name: "Branch Merge Parameters"
          command: |
            echo "previous: << pipeline.parameters.previous_branch >>, main: << pipeline.parameters.main_branch >>, next: << pipeline.parameters.next_branch >>"
      - when:
          condition: << pipeline.parameters.next_branch >>
          steps:
            - cached-checkout-for-pushing
            - run:
                name: Checkout target branch and merge from source
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  git fetch --all
                  git checkout << pipeline.parameters.next_branch >>
                  git reset --hard origin/<< pipeline.parameters.next_branch >>
                  git merge origin/<< pipeline.parameters.main_branch >>
            - run:
                name: Push to github
                command: git push -f origin << pipeline.parameters.next_branch >>:merge-foundation/<< pipeline.parameters.main_branch_label >>-to-<< pipeline.parameters.next_branch_label >>

  # note, this is always run as part of the _next_ branch
  # for example, if main_branch is `foundation-2016` and next_branch is `foundation-2017`,
  # it will include the contents of the `foundation-2017` branch, thus we need to actually
  # look _backwards_ to the previous_branch and main_branch to merge the correct bits.
  merge-foundation-branch:
    <<: *docker_container_config
    steps:
      - run:
          name: "Branch Merge Parameters"
          command: |
            echo "previous: << pipeline.parameters.previous_branch >>, main: << pipeline.parameters.main_branch >>, next: << pipeline.parameters.next_branch >>"
      - when:
          condition: << pipeline.parameters.previous_branch >>
          steps:
            - cached-checkout-for-pushing
            - run:
                name: Checkout target and merge with merge branch
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  git fetch --all
                  git checkout << pipeline.parameters.main_branch >>
                  git reset --hard origin/<< pipeline.parameters.main_branch >>
                  git merge origin/merge-foundation/<< pipeline.parameters.previous_branch_label >>-to-<< pipeline.parameters.main_branch_label >>
            - run:
                name: Push to github
                command: git push origin << pipeline.parameters.main_branch >>:<< pipeline.parameters.main_branch >>

  create-merge-meridian-branch:
    <<: *docker_container_config
    steps:
      - when:
          condition: << pipeline.parameters.main_branch >>
          steps:
            - restore_cache:
                keys:
                  - meridian-v1-{{ .Branch }}-{{ .Revision }}
                  - meridian-v1-{{ .Branch }}-
                  - meridian-v1-
            - cached-checkout-for-pushing
            - run:
                name: Add Meridian remote if necessary
                command: |
                  REMOTE_MERIDIAN="$(git remote | grep -c -E '^meridian$' || :)"
                  if [ "$REMOTE_MERIDIAN" -eq 0 ]; then
                    git remote add meridian git@github.com:OpenNMS/opennms-prime.git
                  fi
            - run:
                name: git fetch meridian
                command: |
                  git fetch meridian
            - save_cache:
                key: meridian-v1-{{ .Branch }}-{{ .Revision }}
                paths:
                  - ".git"
            - run:
                name: Checkout target branch and merge from source
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  if git rev-parse from-<< pipeline.parameters.main_branch >> >/dev/null 2>&1; then
                    git checkout from-<< pipeline.parameters.main_branch >>
                  else
                    git checkout -b from-<< pipeline.parameters.main_branch >> meridian/from-<< pipeline.parameters.main_branch >>
                  fi
                  git reset --hard meridian/from-<< pipeline.parameters.main_branch >>
                  git merge origin/<< pipeline.parameters.main_branch >>
            - run:
                name: Push to Meridian github
                command: git push -f meridian from-<< pipeline.parameters.main_branch >>:from-<< pipeline.parameters.main_branch >>

  merge-poweredby-branch:
    <<: *docker_container_config
    steps:
      - when:
          condition: << pipeline.parameters.main_branch >>
          steps:
            - restore_cache:
                keys:
                  - poweredby-v1-{{ .Branch }}-{{ .Revision }}
                  - poweredby-v1-{{ .Branch }}-
                  - poweredby-v1-
            - cached-checkout-for-pushing
            - run:
                name: Merge Foundation to PoweredBy
                command: .circleci/scripts/merge-poweredby.sh
            - save_cache:
                key: poweredby-v1-{{ .Branch }}-{{ .Revision }}
                paths:
                  - ".git"

  publish-cloudsmith:
    executor: cloudsmith/default
    resource_class: small
    steps:
      - checkout
      - cloudsmith/ensure-api-key
      - cloudsmith/install-cli
      - restore-workflow-assets:
          cache_prefix: deb-horizon
      - restore-workflow-assets:
          cache_prefix: deb-minion
      - restore-workflow-assets:
          cache_prefix: deb-sentinel
      - restore-workflow-assets:
          cache_prefix: rpm-horizon
      - restore-workflow-assets:
          cache_prefix: rpm-minion
      - restore-workflow-assets:
          cache_prefix: rpm-sentinel
      - restore-workflow-assets:
          cache_prefix: minion-config-schema
      - run:
          name: Publish Packages
          command: |
            .circleci/scripts/publish-cloudsmith.sh
