version: 2.1

executors:
  centos-build-executor:
    docker:
      - image: opennms/build-env:11.0.9.11-3.6.3-b5958
  debian-build-executor:
    docker:
      - image: opennms/build-env:debian-jdk11-b6222
  docker-executor:
    docker:
      - image: docker:20.10.1-git
  docs-executor:
    docker:
      - image: opennms/antora:2.3.4-b6293
  integration-test-executor:
    machine:
     image: ubuntu-2004:202010-01
  smoke-test-executor:
    machine:
      image: ubuntu-2004:202010-01

# NOTE: the "_label" versions of these are for the case when your source or target
# branches have slashes in them, that way the merge branch gets created properly
defaults: &defaults
  parameters:
    minimal:
      description: whether to do a minimal (build-and-merge only) build
      type: boolean
      default: false
    previous_branch:
      description: the previous branch, if any
      type: string
      default: release-28.x
    previous_branch_label:
      description: the previous branch, if any (escaped, no slashes)
      type: string
      default: release-28.x
    main_branch:
      description: the auto-merge main branch
      type: string
      default: develop
    main_branch_label:
      description: the auto-merge main branch (escaped, no slashes)
      type: string
      default: develop
    next_branch:
      description: the auto-merge target branch
      type: string
      default: ""
    next_branch_label:
      description: the auto-merge target branch (escaped, no slashes)
      type: string
      default: ""

aliases:
  - &setup_dct_env
    name: Setup DCT environment
    command: |
      case "${CIRCLE_BRANCH}" in
        "master-"*)
           MINION_IMAGE_VERSION="$(~/project/.circleci/scripts/pom2version.sh ~/project/pom.xml)"
          ;;
        "release-"*)
           MINION_IMAGE_VERSION="release-candidate"
          ;;
        "develop")
           MINION_IMAGE_VERSION="bleeding"
          ;;
        *)
          MINION_IMAGE_VERSION=b<< pipeline.number >>
          ;;
      esac
      echo "export DOCKER_CONTENT_TRUST=1" >> $BASH_ENV
      echo "export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=\"$DCT_DELEGATE_KEY_PASSPHRASE\"" >> $BASH_ENV
      echo "export MINION_IMAGE=docker.io/opennms/minion" >> $BASH_ENV
      echo "export MINION_IMAGE_VERSION=\"$MINION_IMAGE_VERSION\"" >> $BASH_ENV
  - &setup_dct_key
    name: Setup DCT key
    command: |
      KEY_FOLDER=~/.docker/trust/private
      mkdir -p $KEY_FOLDER
      # the key that is used to sign single-arch images
      echo "$DCT_DELEGATE_KEY" | base64 -d > $KEY_FOLDER/$DCT_DELEGATE_KEY_NAME.key
      # the key that is used by Notary to sign the multi-arch minion image
      echo "$DCT_REPO_MINION_KEY" | base64 -d > $KEY_FOLDER/$DCT_REPO_MINION_KEY_NAME.key
      chmod 600 $KEY_FOLDER/*
      # setup_dct_env must have been run first because it provide DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE
      # that is required for loading the
      docker trust key load $KEY_FOLDER/$DCT_DELEGATE_KEY_NAME.key
docker_container_config: &docker_container_config
  executor: docker-executor

orbs:
  cloudsmith: cloudsmith/cloudsmith@1.0.3
  sign-packages: opennms/sign-packages@2.1.3

commands:
  extract-pom-version:
      description: "Extracting Maven POM version"
      steps:
        - run:
            name: Extract Maven POM version
            command: .circleci/scripts/pom2version.sh pom.xml > pom-version-cache.key
  cached-checkout:
      description: "Checkout with caching"
      steps:
        - restore_cache:
            keys:
              - source-v1-{{ .Branch }}-{{ .Revision }}
              - source-v1-{{ .Branch }}-
              - source-v1-
        - checkout
        - run:
            name: git config merge.renameLimit
            command: git config merge.renameLimit 999999
        - run:
            name: git fetch origin
            command: git fetch origin
        - save_cache:
            key: source-v1-{{ .Branch }}-{{ .Revision }}
            paths:
              - ".git"
  cached-checkout-for-pushing:
      description: "Configure a cached checkout that can push upstream"
      steps:
        - add_ssh_keys:
            fingerprints:
              - "5e:70:a4:1a:f3:9f:39:ca:2a:d9:b5:9a:6c:2b:c3:66"
        - cached-checkout
        - run:
            name: Create git identity
            command: |
              git config user.email "cicd-system@opennms.com"
              git config user.name "CI/CD System"
  restore-maven-cache:
      description: "Maven: Calculate cache key and restore cache"
      steps:
        - run:
            name: Calculate cache key from pom files
            command: find . -type f -name "pom.xml" | grep -v /target/ | sort -u | xargs cat > maven-dependency-pom-cache.key
        - restore_cache:
            keys:
              - maven-dependencies-v3-{{ checksum "pom-version-cache.key" }}-{{ checksum "maven-dependency-pom-cache.key" }}
              - maven-dependencies-v3-{{ checksum "pom-version-cache.key" }}-
  update-maven-cache:
      description: "Maven: Refresh local repository from POM files"
      steps:
        - run:
            name: Remove old artifacts to keep workspace size down
            command: .circleci/scripts/clean-m2.sh
        - run:
            name: Collect Maven Dependencies
            command: |
              ./compile.pl -t \
                -Dbuild.skip.tarball=true \
                -DupdatePolicy=never \
                --update-plugins \
                -Daether.connector.resumeDownloads=false \
                -Daether.connector.basic.threads=8 \
                -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
                -Pbuild-bamboo \
                -Prun-expensive-tasks \
                -Psmoke \
                --legacy-local-repository \
                --batch-mode \
                dependency:resolve-plugins \
                de.qaware.maven:go-offline-maven-plugin:resolve-dependencies
  save-maven-cache:
    description: "Maven: Save cache"
    steps:
      - save_cache:
          key: maven-dependencies-v3-{{ checksum "pom-version-cache.key" }}-{{ checksum "maven-dependency-pom-cache.key" }}
          paths:
            - ~/.m2
  restore-nodejs-cache:
      description: "NodeJS: Calculate cache key and restore cache"
      steps:
        - run:
            name: Calculate cache key
            command: find core/web-assets -name package\*.json -o -name bower.json | grep -v /target/ | sort -u | xargs cat > nodejs-dependency-json-cache.key
        - restore_cache:
            keys:
              - nodejs-dependencies-v2-{{ checksum "pom-version-cache.key" }}-{{ checksum "nodejs-dependency-json-cache.key" }}
              - nodejs-dependencies-v2-{{ checksum "pom-version-cache.key" }}-
  save-nodejs-cache:
    description: "NodeJS: Save cache"
    steps:
      - save_cache:
          key: nodejs-dependencies-v2-{{ checksum "pom-version-cache.key" }}-{{ checksum "nodejs-dependency-json-cache.key" }}
          paths:
            - core/web-assets/node_modules
  restore-sonar-cache:
      description: "Sonar: Restore sonar cache"
      steps:
        - restore_cache:
            keys:
              - sonar-cache-v2-{{ checksum "pom-version-cache.key" }}
  save-sonar-cache:
      description: "Sonar: Save sonar cache"
      steps:
        - save_cache:
            key: sonar-cache-v2-{{ checksum "pom-version-cache.key" }}
            paths:
              - ~/.sonar
  dockerhub-login:
    description: "Connect to DockerHub"
    steps:
      - run:
          name: Login to DockerHub
          command: |
            if [ -n "${DOCKERHUB_LOGIN}" ]; then
              docker login -u ${DOCKERHUB_LOGIN} -p ${DOCKERHUB_PASS}
            else
              echo "WARNING: dockerhub login not found. Assuming this is a PR or other external branch build."
            fi
  run-smoke-tests:
    description: "Run the smoke tests"
    parameters:
      suite:
        default: core
        type: string
    steps:
      - run:
          name: Enable swap
          command: |
            sudo fallocate -l 8G /swapfile
            sudo chmod 600 /swapfile
            sudo mkswap /swapfile
            sudo swapon /swapfile
            sudo sysctl vm.swappiness=5
            cat /proc/sys/vm/swappiness
      - load-oci:
          key: horizon
      - load-oci:
          key: minion
      - load-oci:
          key: sentinel
      - run:
          name: Monitor JVM processes
          background: true
          command: |
            .circleci/scripts/jvmprocmon-start.sh
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Smoke Tests
          no_output_timeout: 30m
          command: |
            .circleci/scripts/smoke.sh << parameters.suite >>
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/test-results/system-logs
            (dmesg || :) > ~/test-results/system-logs/dmesg 2>&1
            (ps auxf || :) > ~/test-results/system-logs/ps 2>&1
            (free -m || :) > ~/test-results/system-logs/free 2>&1
            (docker stats --no-stream || :) > ~/test-results/system-logs/docker_stats 2>&1
            cp -R /tmp/jvmprocmon ~/test-results/system-logs/ || :
            ls -alh ~/project/smoke-test/ || :
      - run:
          name: Gather test artifacts
          when: always
          command: |
            mkdir -p ~/test-results/junit
            find . -type f -regex ".*/target/surefire-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
            find . -type f -regex ".*/target/failsafe-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
            mkdir -p ~/test-artifacts/recordings
            cp -R ~/project/smoke-test/target/*.flv ~/test-artifacts/recordings || true
            cp -R ~/project/smoke-test/target/screenshots ~/test-artifacts/ || true
            cp -R ~/project/smoke-test/target/logs ~/test-artifacts/ || true
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          when: always
          path: ~/test-results
          destination: test-results
      - store_artifacts:
          when: always
          path: ~/test-artifacts
          destination: test-artifacts
  run-build:
    description: "Run the main build"
    parameters:
      number-vcpu:
        default: 8
        type: integer
      node-memory:
        default: echo "NODE_OPTIONS Not Set"
        type: string
      vaadin-javamaxmem:
        default: 1g
        type: string
    steps:
      - cached-checkout
      - extract-pom-version
      - run:
          name: Check for Releasability
          command: |
            export OPENNMS_VERSION="$(.circleci/scripts/pom2version.sh pom.xml)"
            .circleci/scripts/release-lint.sh "${OPENNMS_VERSION}"
      - restore-maven-cache
      - restore-nodejs-cache
      - run:
          name: Compile OpenNMS
          command: |
            .circleci/scripts/configure-signing.sh
            ./clean.pl
            << parameters.node-memory >>
            ./compile.pl -DskipTests=true -Dbuild.skip.tarball=false \
              -DupdatePolicy=never \
              -Daether.connector.resumeDownloads=false \
              -Daether.connector.basic.threads=1 \
              -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
              -DvaadinJavaMaxMemory=<< parameters.vaadin-javamaxmem >> \
              -DmaxCpus=<< parameters.number-vcpu >> \
              -Psmoke \
              install --batch-mode
      - update-maven-cache
      - run:
          name: Remove Extra Maven Repository OpenNMS Files
          command: |
            # move these out of the way so they're not stored in the maven pre-cache
            cd ~/.m2/repository/org/opennms
            mkdir /tmp/maven-keep
            mv $(ls -1 | grep -v -E '^(jicmp-api|jicmp6-api|jrrd-api|jrrd2-api|lib|maven)$') /tmp/maven-keep
      - save-maven-cache
      - run:
          name: Restore Extra Maven Repository OpenNMS Files
          command: |
            # now move them back so they end up in the workspace for builds further down the workflow
            mv /tmp/maven-keep/* ~/.m2/repository/org/opennms/
      - save-nodejs-cache
      - persist_to_workspace:
          root: ~/
          paths:
            - project
            - .m2
  run-integration-tests:
    parameters:
      run-code-coverage:
        default: false
        type: boolean
      rerun-failtest-count:
        default: 0
        type: integer
      failure-option:
        default: -fae
        type: string
      changes-only:
        default: true
        type: boolean
    steps:
      - update-maven-cache
      - run:
          name: Monitor JVM processes
          background: true
          command: |
            .circleci/scripts/jvmprocmon-start.sh
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Integration Tests
          no_output_timeout: 15m
          command: |
            export CCI_CODE_COVERAGE=<< parameters.run-code-coverage >>
            export CCI_RERUN_FAILTEST=<< parameters.rerun-failtest-count >>
            export CCI_FAILURE_OPTION=<< parameters.failure-option >>
            export CCI_CHANGES_ONLY=<< parameters.changes-only >>
            .circleci/scripts/itest.sh
      - run:
          name: Gather test results
          when: always
          command: |
            mkdir -p ~/test-results/junit
            find . -type f -regex ".*/target/.*-reports-[0-9]+/.*xml" -exec cp {} ~/test-results/junit/ \;
            find . -type f -regex ".*/target/.*-reports-[0-9]+/.*dump.*" -exec cp {} ~/test-results/junit/ \;
      - run:
          name: Gather tests
          when: always
          command: |
            mkdir -p ~/generated-tests
            cp ./surefire_classname* ~/generated-tests/
            cp ./failsafe_classname* ~/generated-tests/
            cp /tmp/this_node* ~/generated-tests/
      - when:
          condition: << parameters.run-code-coverage >>
          steps:
            - run:
                name: Compress Target Directories (Code Coverage)
                when: always
                command: |
                  .circleci/scripts/codecoverage-save.sh
            - persist_to_workspace:
                root: ~/
                paths:
                  - code-coverage
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/build-results/system-logs
            (dmesg || :) > ~/build-results/system-logs/dmesg 2>&1
            (ps auxf || :) > ~/build-results/system-logs/ps 2>&1
            (free -m || :) > ~/build-results/system-logs/free 2>&1
            (docker stats --no-stream || :) > ~/build-results/system-logs/docker_stats 2>&1
            cp -R /tmp/jvmprocmon ~/build-results/system-logs/ || :
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          when: always
          path: ~/test-results
          destination: test-results
      - store_artifacts:
          when: always
          path: ~/build-results
          destination: build-results
      - store_artifacts:
          when: always
          path: ~/generated-tests
          destination: generated-tests
  cache-workflow-assets:
    parameters:
      cache_prefix:
        description: the cache prefix
        type: string
      source_path:
        description: the source directory to cache
        type: string
    steps:
      - run:
          name: Stowing Assets in << parameters.source_path >> to cache prefix << parameters.cache_prefix >>
          command: |
            TARGET_PATH="/tmp/<< parameters.cache_prefix >>"
            rsync -ar "$(echo "<< parameters.source_path >>" | sed -e 's,/*$,,')/" "${TARGET_PATH}/"
            find "${TARGET_PATH}" -type d -print0 | xargs -0 chmod 775
            find "${TARGET_PATH}" ! -type d -print0 | xargs -0 chmod 664
      - save_cache:
          key: << parameters.cache_prefix >>-v2-{{ .Branch }}-{{ .Revision }}-{{ .Environment.CIRCLE_WORKFLOW_ID }}
          paths:
            - "/tmp/<< parameters.cache_prefix >>"
  restore-workflow-assets:
    parameters:
      cache_prefix:
        description: the cache prefix
        type: string
      target_path:
        description: the target directory to restore into
        type: string
        default: ""
    steps:
      - restore_cache:
          keys:
            - << parameters.cache_prefix >>-v2-{{ .Branch }}-{{ .Revision }}-{{ .Environment.CIRCLE_WORKFLOW_ID }}
            - << parameters.cache_prefix >>-v2-{{ .Branch }}-{{ .Revision }}-
      - when:
          condition: << parameters.target_path >>
          steps:
            - run:
                name: Restoring assets to << parameters.target_path >> from cached prefix << parameters.cache_prefix >>
                command: |
                  SOURCE_PATH="/tmp/<< parameters.cache_prefix >>"
                  mkdir -p "<< parameters.target_path >>"
                  rsync -ar "${SOURCE_PATH}/" "$(echo "<< parameters.target_path >>" | sed -e 's,/*$,,')/"
  cache-oci:
    parameters:
      key:
        description: the cache key for storing the OCI
        type: string
      path:
        description: the path to the directory containing the OCI
        type: string
    steps:
      - cache-workflow-assets:
          cache_prefix: oci-<< parameters.key >>
          source_path: << parameters.path >>
  load-oci:
    parameters:
      key:
        description: the OCI cache key to restore
        type: string
    steps:
      - restore-workflow-assets:
          cache_prefix: oci-<< parameters.key >>
      - run:
          name: Load Docker Image(s) in oci-<< parameters.key >>
          command: |
            cd "/tmp/oci-<< parameters.key >>"
            if [ "$(ls -1 *.oci | wc -l)" -eq 0 ]; then
              echo "ERROR: No OCI files to load. Something probably went wrong earlier."
              exit 1
            fi
            for FILE in *.oci; do
              echo "Loading ${FILE} into Docker..."
              docker image load -i "$FILE"
            done

workflows:
  weekly-coverage:
    <<: *defaults
    when:
      equal: [ false, << parameters.minimal >> ]
    triggers:
      - schedule:
          # Saturday at 12:00 AM
          cron: "0 0 * * 6"
          filters:
            branches:
              only:
                - develop
    jobs:
      - build
      - integration-test-with-coverage:
          requires:
            - build
      - code-coverage:
          requires:
            - integration-test-with-coverage
  build-minimal:
    <<: *defaults
    when:
      equal: [ true, << parameters.minimal >> ]
    jobs:
      - build
      - create-merge-foundation-branch:
          requires:
            - build
          filters:
            branches:
              only: << parameters.main_branch >>
      - merge-foundation-branch:
          requires:
            - build
          filters:
            branches:
              only: merge-foundation/<< parameters.previous_branch_label >>-to-<< parameters.main_branch_label >>
      - create-merge-meridian-branch:
          requires:
            - build
          filters:
            branches:
              only: /^foundation.*/
      - merge-poweredby-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - build
          filters:
            branches:
              only:
                - /^foundation.*/
  build-deploy:
    <<: *defaults
    when:
      equal: [ false, << parameters.minimal >> ]
    jobs:
      - build:
          filters:
            branches:
              ignore:
                - /^from-foundation.*/
      - build-docs:
          filters:
            branches:
              ignore:
                - /^from-foundation.*/
      - tarball-assembly:
          requires:
            - build
      - minion-image-single-arch:
          matrix:
            parameters:
              architecture: [linux/amd64,linux/arm64,linux/arm/v7]
          context: "docker-content-trust"
          requires:
            - tarball-assembly
            - smoke-test-minion
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
      - minion-image-multi-arch:
          context: "docker-content-trust"
          requires:
            - minion-image-single-arch
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
      - horizon-rpm-build:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - minion-rpm-build:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - sentinel-rpm-build:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - integration-test:
          requires:
            - build
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - smoke-test-core:
          requires:
            - horizon-rpm-build
            - tarball-assembly
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-minion:
          requires:
            - horizon-rpm-build
            - tarball-assembly
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-sentinel:
          requires:
            - horizon-rpm-build
            - tarball-assembly
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - smoke-test-minimal:
          requires:
            - horizon-rpm-build
            - tarball-assembly
            - sentinel-rpm-build
          filters:
            branches:
              ignore:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/
                - /^merge-foundation.*/
                - /^features.*/
                - /.*smoke.*/
                - /^dependabot.*/
      - horizon-publish-oci:
          requires:
            - horizon-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
      - sentinel-publish-oci:
          requires:
            - sentinel-rpm-build
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
      # These don't actually require `integration-test` but we shouldn't bother
      # spending cycles unless everything else passed
      - horizon-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - minion-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - sentinel-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              ignore:
                - /^merge-foundation.*/
      - create-merge-foundation-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - smoke-test-core
            - smoke-test-minion
            - smoke-test-sentinel
            - smoke-test-minimal
            - integration-test
          filters:
            branches:
              only: << parameters.main_branch >>
      - merge-foundation-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - tarball-assembly
          filters:
            branches:
              only: merge-foundation/<< parameters.previous_branch_label >>-to-<< parameters.main_branch_label >>
      - create-merge-meridian-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - smoke-test-core
            - smoke-test-minion
            - smoke-test-sentinel
            - smoke-test-minimal
            - integration-test
          filters:
            branches:
              only: /^foundation.*/
      - merge-poweredby-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - smoke-test-core
            - smoke-test-minion
            - smoke-test-sentinel
            - smoke-test-minimal
            - integration-test
          filters:
            branches:
              only:
                - /^foundation.*/
      - publish-cloudsmith:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - minion-deb-build
            - sentinel-deb-build
            - smoke-test-core
            - smoke-test-minion
            - smoke-test-sentinel
            - smoke-test-minimal
            - integration-test
          filters:
            branches:
              only:
                - develop
                - /^master-.*/
                - /^release-.*/
                - /^foundation.*/

jobs:
  build:
    executor: centos-build-executor
    # Building currently requires the xlarge containers in order for the webpack compilation
    # in the core/web-assets module to complete reliably
    resource_class: xlarge
    steps:
      - run-build:
          number-vcpu: 8
  build-docs:
    executor: docs-executor
    steps:
      - cached-checkout
      - run:
          name: Validate Xrefs in docs
          command: |
            NODE_PATH="$(npm -g root)" antora --generator @antora/xref-validator antora-playbook-local.yml
      - run:
          name: Build docs with Antora
          command: |
             DOCSEARCH_ENABLED=true DOCSEARCH_ENGINE=lunr NODE_PATH="$(npm -g root)" antora --generator antora-site-generator-lunr --stacktrace generate antora-playbook-local.yml
      - store_artifacts:
          path: ~/project/build/site.zip
          destination: site.zip
  tarball-assembly:
    machine:
      image: ubuntu-2004:202010-01
      docker_layer_caching: true
    resource_class: large
    environment:
      DOCKER_CLI_EXPERIMENTAL: enabled
    parameters:
      number-vcpu:
        default: 4
        type: integer
      vaadin-javamaxmem:
        default: 1g
        type: string
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: multiarch/qemu-user-static
          command: docker run --privileged multiarch/qemu-user-static --reset -p yes
      - run:
          name: Install Docker buildx
          command: |
            sudo wget https://github.com/docker/buildx/releases/download/v0.5.1/buildx-v0.5.1.linux-amd64 -O /usr/local/bin/docker-buildx
            sudo chmod a+x /usr/local/bin/docker-buildx
            sudo systemctl restart docker
      - dockerhub-login
      - run:
          name: Assemble tarballs and related artifacts
          command: |
            export MAVEN_OPTS="-Xmx4g -Xms4g"
            # general assembly
            date
            ./compile.pl -DskipTests=true -Dbuild.skip.tarball=false \
              -DupdatePolicy=never \
              -Daether.connector.resumeDownloads=false \
              -Daether.connector.basic.threads=1 \
              -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
              -DvaadinJavaMaxMemory=<< parameters.vaadin-javamaxmem >> \
              -DmaxCpus=<< parameters.number-vcpu >> \
              -Pbuild-bamboo \
              -Prun-expensive-tasks \
              -Dopennms.home=/opt/opennms \
              install --batch-mode
            # javadoc
            date
            ./compile.pl -DskipTests=true -Dbuild.skip.tarball=false \
              -DupdatePolicy=never \
              -Daether.connector.resumeDownloads=false \
              -Daether.connector.basic.threads=1 \
              -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
              -DvaadinJavaMaxMemory=<< parameters.vaadin-javamaxmem >> \
              -DmaxCpus=<< parameters.number-vcpu >> \
              -Pbuild-bamboo \
              -Prun-expensive-tasks \
              -Dopennms.home=/opt/opennms \
              javadoc:aggregate --batch-mode
            date
      - run:
          name: Build Minion OCI
          command: |
            cd opennms-container/minion

            # Create always a downloadable single OCI artifact for AMD architecture.
            # This image is used in our integration test suite which relies on the tag "minion:latest".
            make VERSION="$(../pom2version.py ../../pom.xml)" \
                 DOCKER_TAG="minion:latest" \
                 BUILD_NUMBER="${CIRCLE_BUILD_NUM}" \
                 BUILD_URL="${CIRCLE_BUILD_URL}" \
                 BUILD_BRANCH="${CIRCLE_BRANCH}"

      - run:
          name: Collect Artifacts
          command: |
            mkdir -p target/{artifacts,config-schema,tarballs}
            OPENNMS_VERSION="$(.circleci/scripts/pom2version.sh pom.xml)"
            find ./target -name "*.tar.gz" -type f -not -iname '*source*' -exec cp {} "./target/tarballs/opennms-${OPENNMS_VERSION}.tar.gz" \;
            find ./opennms-assemblies/minion/target -name "*.tar.gz" -type f -not -iname '*source*' -exec cp {} "./target/tarballs/minion-${OPENNMS_VERSION}.tar.gz" \;
            find ./opennms-assemblies/sentinel/target -name "*.tar.gz" -type f -not -iname '*source*' -exec cp {} "./target/tarballs/sentinel-${OPENNMS_VERSION}.tar.gz" \;
            pushd target/site/apidocs
              tar -czf "../../artifacts/opennms-${OPENNMS_VERSION}-javadoc.tar.gz" *
            popd
            cp ./opennms-assemblies/xsds/target/*-xsds.tar.gz "./target/artifacts/opennms-${OPENNMS_VERSION}-xsds.tar.gz"
            cp target/*-source.tar.gz ./target/artifacts/
            cp opennms-container/minion/minion-config-schema.yml "./target/config-schema/"
      - store_artifacts:
          when: always
          path: ~/project/target/artifacts
          destination: artifacts
      - store_artifacts:
          when: always
          path: ~/project/target/config-schema
          destination: config-schema
      - store_artifacts:
          when: always
          path: ~/project/target/tarballs
          destination: tarballs
      - store_artifacts:
          path: ~/project/opennms-container/minion/images/minion.oci
          destination: minion.oci
      - cache-workflow-assets:
          cache_prefix: minion-config-schema
          source_path: target/config-schema/
      - cache-oci:
          key: minion
          path: opennms-container/minion/images/
      - persist_to_workspace:
          root: ~/
          paths:
            - project/opennms-assemblies/minion/target/org.opennms.assemblies.minion-*-minion.tar.gz

  minion-image-single-arch:
    parameters:
      architecture:
        type: string
    machine:
      image: ubuntu-2004:202010-01
    environment:
      DOCKER_CLI_EXPERIMENTAL: enabled
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: multiarch/qemu-user-static
          command: docker run --privileged multiarch/qemu-user-static --reset -p yes
      - run:
          name: Install Docker buildx
          command: |
            sudo wget https://github.com/docker/buildx/releases/download/v0.5.1/buildx-v0.5.1.linux-amd64 -O /usr/local/bin/docker-buildx
            sudo chmod a+x /usr/local/bin/docker-buildx
            sudo systemctl restart docker
      - dockerhub-login
      - run: *setup_dct_env
      - run: *setup_dct_key
      - run:
          name: Single-arch build & push
          command: |
            cd opennms-container/minion
            ARCH="$(printf "<< parameters.architecture >>" | tr / -)"
            TAG="${MINION_IMAGE_VERSION}-${ARCH}"
            make DOCKER_ARCH="<< parameters.architecture >>" \
                 DOCKER_FLAGS=--load \
                 VERSION="${TAG}" \
                 BUILD_NUMBER="${CIRCLE_BUILD_NUM}" \
                 BUILD_URL="${CIRCLE_BUILD_URL}" \
                 BUILD_BRANCH="${CIRCLE_BRANCH}"
            docker push ${MINION_IMAGE}:${TAG}

  minion-image-multi-arch:
    machine:
      image: ubuntu-2004:202010-01
    environment:
      DOCKER_CLI_EXPERIMENTAL: enabled
    steps:
      - attach_workspace:
          at: ~/
      - dockerhub-login
      - run: *setup_dct_env
      - run: *setup_dct_key
      - run:
          name: Install notary
          command: |
            sudo wget https://github.com/theupdateframework/notary/releases/download/v0.6.1/notary-Linux-amd64 -O /usr/local/bin/notary
            sudo chmod a+x /usr/local/bin/notary
      - run:
          name: Create & push multi-arch manifest
          command: |
            IMAGE_REF="${MINION_IMAGE}:${MINION_IMAGE_VERSION}"
            docker manifest create ${IMAGE_REF} \
              ${IMAGE_REF}-linux-amd64 \
              ${IMAGE_REF}-linux-arm64 \
              ${IMAGE_REF}-linux-arm-v7 \
              --amend
            SHA_256="$(docker manifest push "${IMAGE_REF}" --purge | cut -d ':' -f 2)"
            echo "Manifest SHA-256: ${SHA_256}"
            echo "Image-Ref: ${IMAGE_REF}"
            MANIFEST_FROM_REG="$(docker manifest inspect "${IMAGE_REF}" -v)";
            BYTES_SIZE="$(printf "${MANIFEST_FROM_REG}" | jq -r '.[].Descriptor.size' | uniq)";
            echo "Manifest-inspect BYTES: ${BYTES_SIZE}";
            echo "Manifest contents:\n";
            printf "${MANIFEST_FROM_REG}" | jq -r '.[].Descriptor | "Architecture: " + .platform.architecture + .platform.variant + ", digest: " + .digest';
            export NOTARY_AUTH="$(printf "${DOCKERHUB_LOGIN}:${DOCKERHUB_PASS}" | base64 -w0)"
            echo "Sign ${SHA_256} with the notary"
            # when the multi-arch image is signed by the delegate key then docker pull reports "No valid trust data..."
            # -> the following lines can not be used:
            #
            # export NOTARY_DELEGATION_PASSPHRASE="${DCT_DELEGATE_KEY_PASSPHRASE}"
            # notary -d ~/.docker/trust/ -s https://notary.docker.io addhash "${MINION_IMAGE}" "${MINION_IMAGE_VERSION}" 946 --sha256 "${SHA_256}" --roles targets/opennms-circle-delegate --publish --verbose
            #
            # -> use the targets key of the minion repository to sign the multi-arch image instead
            export NOTARY_TARGETS_PASSPHRASE="${DCT_REPO_MINION_KEY_PASSPHRASE}"
            notary -d ~/.docker/trust/ -s https://notary.docker.io addhash "${MINION_IMAGE}" "${MINION_IMAGE_VERSION}" "${BYTES_SIZE}" --sha256 "${SHA_256}" --publish --verbose
            echo "Done!"
            # notary -s https://notary.docker.io list "${IMAGE}"

  horizon-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            .circleci/scripts/makerpm.sh tools/packages/opennms/opennms.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Fetch RPM artifacts and build Horizon container image
          command: |
            cd opennms-container/horizon
            ./build_container_image.sh
      - store_artifacts:
          path: ~/project/opennms-container/horizon/images/container.oci
          destination: horizon.oci
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - cache-workflow-assets:
          cache_prefix: rpm-horizon
          source_path: target/rpm/RPMS/noarch
      - cache-oci:
          key: horizon
          path: opennms-container/horizon/images/
  minion-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    # Will need to increase resource class if horizon-rpm-build is under 15 min
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            .circleci/scripts/makerpm.sh tools/packages/minion/minion.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - cache-workflow-assets:
          cache_prefix: rpm-minion
          source_path: target/rpm/RPMS/noarch
  sentinel-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    # Will need to increase resource class if horizon-rpm-build is under 19 min
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            .circleci/scripts/makerpm.sh tools/packages/sentinel/sentinel.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Fetch RPM artifacts and build Sentinel container image
          command: |
            cd opennms-container/sentinel
            ./build_container_image.sh
      - store_artifacts:
          path: ~/project/opennms-container/sentinel/images/container.oci
          destination: sentinel.oci
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - cache-workflow-assets:
          cache_prefix: rpm-sentinel
          source_path: target/rpm/RPMS/noarch
      - cache-oci:
          key: sentinel
          path: opennms-container/sentinel/images/
  horizon-deb-build:
    executor: debian-build-executor
    resource_class: xlarge
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=2
            .circleci/scripts/makedeb.sh opennms
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/build-results/system-logs
            (dmesg || :) > ~/build-results/system-logs/dmesg 2>&1
            (ps auxf || :) > ~/build-results/system-logs/ps 2>&1
            (free -m || :) > ~/build-results/system-logs/free 2>&1
            (docker stats --no-stream || :) > ~/build-results/system-logs/docker_stats 2>&1
            cp -R /tmp/jvmprocmon ~/build-results/system-logs/ || :
      - store_artifacts:
          when: always
          path: ~/build-results
          destination: build-results
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - cache-workflow-assets:
          cache_prefix: deb-horizon
          source_path: target/debs
  minion-deb-build:
    executor: debian-build-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            .circleci/scripts/makedeb.sh minion
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - cache-workflow-assets:
          cache_prefix: deb-minion
          source_path: target/debs
  sentinel-deb-build:
    executor: debian-build-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            .circleci/scripts/makedeb.sh sentinel
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - cache-workflow-assets:
          cache_prefix: deb-sentinel
          source_path: target/debs
  horizon-publish-oci:
    executor: centos-build-executor
    steps:
      - cached-checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - dockerhub-login
      - load-oci:
          key: horizon
      - run:
          name: tag horizon Docker image and publish to registry
          command: |
            cd opennms-container/horizon
            ./tag.sh
            ./publish.sh
  sentinel-publish-oci:
    executor: centos-build-executor
    steps:
      - cached-checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - dockerhub-login
      - load-oci:
          key: sentinel
      - run:
          name: tag sentinel Docker image and publish to registry
          command: |
            cd opennms-container/sentinel
            ./tag.sh
            ./publish.sh
  integration-test:
    executor: integration-test-executor
    parallelism: 4
    steps:
      - attach_workspace:
          at: ~/
      - run-integration-tests:
          rerun-failtest-count: 1
  integration-test-with-coverage:
    executor: integration-test-executor
    parallelism: 8
    steps:
      - attach_workspace:
          at: ~/
      - run-integration-tests:
          run-code-coverage: true
          rerun-failtest-count: 0
          failure-option: -fn
          changes-only: false
  code-coverage:
    executor: centos-build-executor
    resource_class: medium
    steps:
      - attach_workspace:
          at: ~/
      - extract-pom-version
      - restore-sonar-cache
      - run:
          name: Restore Target Directories (Code Coverage)
          when: always
          command: |
            .circleci/scripts/codecoverage-restore.sh
      - run:
          name: Run SonarQube Code Analysis
          when: always
          command: |
            export MAVEN_OPTS="-Xms3G -Xmx3G"
            .circleci/scripts/sonar.sh
      - save-sonar-cache
  smoke-test-core:
    executor: smoke-test-executor
    parallelism: 6
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: core
  smoke-test-minion:
    executor: smoke-test-executor
    parallelism: 4
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: minion
  smoke-test-sentinel:
    executor: smoke-test-executor
    parallelism: 5
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: sentinel
  smoke-test-minimal:
    executor: smoke-test-executor
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          suite: minimal
  create-merge-foundation-branch:
    <<: *defaults
    <<: *docker_container_config
    steps:
      - run:
          name: "Branch Merge Parameters"
          command: |
            echo "previous: << parameters.previous_branch >>, main: << parameters.main_branch >>, next: << parameters.next_branch >>"
      - when:
          condition: << parameters.next_branch >>
          steps:
            - cached-checkout-for-pushing
            - run:
                name: Checkout target branch and merge from source
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  git fetch --all
                  git checkout << parameters.next_branch >>
                  git reset --hard origin/<< parameters.next_branch >>
                  git merge origin/<< parameters.main_branch >>
            - run:
                name: Push to github
                command: git push -f origin << parameters.next_branch >>:merge-foundation/<< parameters.main_branch_label >>-to-<< parameters.next_branch_label >>

  # note, this is always run as part of the _next_ branch
  # for example, if main_branch is `foundation-2016` and next_branch is `foundation-2017`,
  # it will include the contents of the `foundation-2017` branch, thus we need to actually
  # look _backwards_ to the previous_branch and main_branch to merge the correct bits.
  merge-foundation-branch:
    <<: *defaults
    <<: *docker_container_config
    steps:
      - run:
          name: "Branch Merge Parameters"
          command: |
            echo "previous: << parameters.previous_branch >>, main: << parameters.main_branch >>, next: << parameters.next_branch >>"
      - when:
          condition: << parameters.previous_branch >>
          steps:
            - cached-checkout-for-pushing
            - run:
                name: Checkout target and merge with merge branch
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  git fetch --all
                  git checkout << parameters.main_branch >>
                  git reset --hard origin/<< parameters.main_branch >>
                  git merge origin/merge-foundation/<< parameters.previous_branch_label >>-to-<< parameters.main_branch_label >>
            - run:
                name: Push to github
                command: git push origin << parameters.main_branch >>:<< parameters.main_branch >>

  create-merge-meridian-branch:
    <<: *defaults
    <<: *docker_container_config
    steps:
      - when:
          condition: << parameters.main_branch >>
          steps:
            - restore_cache:
                keys:
                  - meridian-v1-{{ .Branch }}-{{ .Revision }}
                  - meridian-v1-{{ .Branch }}-
                  - meridian-v1-
            - cached-checkout-for-pushing
            - run:
                name: Add Meridian remote if necessary
                command: |
                  REMOTE_MERIDIAN="$(git remote | grep -c -E '^meridian$' || :)"
                  if [ "$REMOTE_MERIDIAN" -eq 0 ]; then
                    git remote add meridian git@github.com:OpenNMS/opennms-prime.git
                  fi
            - run:
                name: git fetch meridian
                command: |
                  git fetch meridian
            - save_cache:
                key: meridian-v1-{{ .Branch }}-{{ .Revision }}
                paths:
                  - ".git"
            - run:
                name: Checkout target branch and merge from source
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  if git rev-parse from-<< parameters.main_branch >> >/dev/null 2>&1; then
                    git checkout from-<< parameters.main_branch >>
                  else
                    git checkout -b from-<< parameters.main_branch >> meridian/from-<< parameters.main_branch >>
                  fi
                  git reset --hard meridian/from-<< parameters.main_branch >>
                  git merge origin/<< parameters.main_branch >>
            - run:
                name: Push to Meridian github
                command: git push -f meridian from-<< parameters.main_branch >>:from-<< parameters.main_branch >>

  merge-poweredby-branch:
    <<: *defaults
    <<: *docker_container_config
    steps:
      - when:
          condition: << parameters.main_branch >>
          steps:
            - restore_cache:
                keys:
                  - poweredby-v1-{{ .Branch }}-{{ .Revision }}
                  - poweredby-v1-{{ .Branch }}-
                  - poweredby-v1-
            - cached-checkout-for-pushing
            - run:
                name: Merge Foundation to PoweredBy
                command: .circleci/scripts/merge-poweredby.sh
            - save_cache:
                key: poweredby-v1-{{ .Branch }}-{{ .Revision }}
                paths:
                  - ".git"

  publish-cloudsmith:
    executor: cloudsmith/default
    resource_class: small
    steps:
      - checkout
      - cloudsmith/ensure-api-key
      - cloudsmith/install-cli
      - restore-workflow-assets:
          cache_prefix: deb-horizon
      - restore-workflow-assets:
          cache_prefix: deb-minion
      - restore-workflow-assets:
          cache_prefix: deb-sentinel
      - restore-workflow-assets:
          cache_prefix: rpm-horizon
      - restore-workflow-assets:
          cache_prefix: rpm-minion
      - restore-workflow-assets:
          cache_prefix: rpm-sentinel
      - restore-workflow-assets:
          cache_prefix: minion-config-schema
      - run:
          name: Publish Packages
          command: |
            .circleci/scripts/publish-cloudsmith.sh

