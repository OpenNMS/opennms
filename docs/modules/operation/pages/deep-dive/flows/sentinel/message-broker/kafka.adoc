.Create a file in etc/featuresBoot.d/flows.boot
[source, console]
----
sudo vi etc/featuresBoot.d/flows.boot
----

.Add the following features to Sentinel on startup
[source, flows.boot]
----
sentinel-jsonstore-postgres
sentinel-blobstore-noop
sentinel-kafka
sentinel-flows
----

.(Optional) Configure a custom topic prefix
[source, console]
----
sudo vi etc/custom.system.properties
----

[source, custom.system.properties]
----
org.opennms.instance.id=OpenNMS<1>
----
<1> Replace `OpenNMS` with the same topic prefix that the target instance of {page-component-title} Core uses.

.Connect to the Karaf shell via SSH
[source, console]
----
ssh -p 8301 admin@localhost
----

.Configure Sentinel tracing and REST endpoint
[source, karaf]
----
config:edit org.opennms.sentinel.controller
config:property-set location SENTINEL<1>
config:property-set id 00000000-0000-0000-0000-000000ddba11<2>
config:update
----
<1> A location string is used to assign the Sentinel to a monitoring location. This can be an existing location or a new location and does not impact the messages that this Sentinel will process.
<2> Unique identifier you define to be used as a node label for monitoring the Sentinel instance within {page-component-title}.
This can be a GUID or a hostname.

.Configure Sentinel as Kafka consumer for flow messages
[source, karaf]
----
config:edit org.opennms.core.ipc.sink.kafka.consumer<1>
config:property-set bootstrap.servers my-kafka-ip-1:9092,my-kafka-ip-2:9092<2>
config:property-set group.id OpenNMS<3>
config:update
----
<1> Edit the configuration for the flow consumer from Kafka.
<2> Connect to the following Kafka nodes and adjust the IPs or FQDNs with the Kafka port (9092) accordingly.
<3> (Optional) When using the same Kafka cluster for multiple {page-component-title} instances, the `group.id` value should be the same as the `org.opennms.instance.id` value in the `etc/custom.system.properties` file.

TIP: The complete set of configuration properties needed for your cluster depends on your Kafka deployment.
Refer to the Kafka configuration that {page-component-title} Core and Minions use, as the properties required for those components will likely be similar to the properties needed in the Sentinel's configuration.


.Configure Sentinel to generate and send events (sink) using the same set of properties from the previous step
[source, karaf]
----
config:edit org.opennms.core.ipc.sink.kafka
config:property-set bootstrap.servers my-kafka-ip-1:9092,my-kafka-ip-2:9092
config:property-set group.id OpenNMS
config:update
----

Exit the Karaf Shell with kbd:[Ctrl+d]

.Restart the Sentinel to apply the configuration
[source, console]
----
sudo systemctl restart sentinel
----

.Run health-check to verify configuration
[source, karaf]
----
opennms:health-check
----

.Ensure features are installed and work properly
[source, output]
----
Verifying the health of the container

Verifying installed bundles                    [ Success  ]
Connecting to Kafka from Sink Producer         [ Success  ]
Connecting to Kafka from Sink Consumer         [ Success  ]
Retrieving NodeDao                             [ Success  ]
Connecting to ElasticSearch ReST API (Flows)   [ Success  ]

=> Everything is awesome
----
