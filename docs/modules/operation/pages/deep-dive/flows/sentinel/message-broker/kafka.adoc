.Create a file in etc/featuresBoot.d/flows.boot
[source, console]
----
sudo vi etc/featuresBoot.d/flows.boot
----

.Add the following features to Sentinel on startup
[source, flows.boot]
----
sentinel-jsonstore-postgres
sentinel-blobstore-noop
sentinel-kafka
sentinel-flows
----

.(Optional) Configure a custom topic prefix
[source, console]
----
sudo vi etc/custom.system.properties
----

[source, custom.system.properties]
----
org.opennms.instance.id=OpenNMS<1>
----

<1> Replace `OpenNMS` with the same topic prefix used by the target instance of {page-component-title} Core.

.Connect to the Karaf shell via SSH
[source, console]
----
ssh -p 8301 admin@localhost
----

.Configure Sentinel tracing and REST endpoint
[source, karaf]
----
config:edit org.opennms.sentinel.controller
config:property-set location SENTINEL<1>
config:property-set id 00000000-0000-0000-0000-000000ddba11<2>
config:update
----

<1> A location string is used to assign the Sentinel to a monitoring location. This can be an existing location or a new location and does not impact the messages that this Sentinel will process.
<2> Unique identifier used as a node label for monitoring the Sentinel instance within {page-component-title}.

.Configure Sentinel as Kafka consumer for flow messages
[source, karaf]
----
config:edit org.opennms.core.ipc.sink.kafka.consumer<1>
config:property-set bootstrap.servers my-kafka-ip-1:9092,my-kafka-ip-2:9092<2>
config:property-set group.id OpenNMS<3>
config:update
----

<1> Edit the configuration for the flow consumer from Kafka.
<2> Connect to the following Kafka nodes and adjust the IPs or FQDNs with the Kafka port (9092) accordingly.
<3> (Optional) Use the same value used for `org.opennms.instance.id` in file `etc/custom.system.properties` as the value of `group.id` when using the same Kafka cluster for multiple {page-component-title} instances.

TIP: The complete set of configuration properties needed for your cluster depends on your Kafka deployment.
Refer to the configuration used for Kafka by {page-component-title} Core and Minion(s) as the properties required for those components will likely be similar to the properties needed in Sentinel's configuration.


.Configure Sentinel to generate and send events (sink) using the same set of properties used in the previous step
[source, karaf]
----
config:edit org.opennms.core.ipc.sink.kafka
config:property-set bootstrap.servers my-kafka-ip-1:9092,my-kafka-ip-2:9092
config:property-set group.id OpenNMS
config:update
----

Exit the Karaf Shell with kbd:[Ctrl+d]

.Restart the Sentinel to apply the configuration
[source, console]
----
sudo systemctl restart sentinel
----

.Run health-check to verify configuration
[source, karaf]
----
opennms:health-check
----

.Ensure features are installed and work properly
[source, output]
----
Verifying the health of the container

Verifying installed bundles                    [ Success  ]
Connecting to Kafka from Sink Producer         [ Success  ]
Connecting to Kafka from Sink Consumer         [ Success  ]
Retrieving NodeDao                             [ Success  ]
Connecting to ElasticSearch ReST API (Flows)   [ Success  ]

=> Everything is awesome
----
