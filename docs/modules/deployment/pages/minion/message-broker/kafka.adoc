.Create a file to prevent installing ActiveMQ features on Minion startup
[source, console]
----
sudo vi etc/featuresBoot.d/disable-activemq.boot
----

.Add the following lines to disable ActiveMQ features and save the file
[source, editor]
----
!minion-jms
!opennms-core-ipc-rpc-jms
!opennms-core-ipc-sink-camel
----

.Create a file to install Kafka features on Minion startup
[source, console]
----
sudo vi etc/featuresBoot.d/kafka.boot
----

.Add the following lines to install the remote producer call (RPC) and sink feature for Kafka on Minion startup and save the file
[source, editor]
----
opennms-core-ipc-rpc-kafka
opennms-core-ipc-sink-kafka
----

.Configure the Kafka features and the Minion location via the Karaf Shell
[source, karaf]
----
ssh -p 8201 admin@localhost
----

.Configure the Minion location and REST endpoint
[source, karaf]
----
config:edit org.opennms.minion.controller<1>
config:property-set location Office-Pittsboro<2>
config:property-set http-url http://core-instance-ip:8980/opennms<3>
config:update<4>
----

<1> Change mode to edit the minion configuration
<2> Replace Office-Pittsboro with a location name representing your remote location the Minion is running
<3> Replace the example `http-url` with the URL of your {page-component-title} Core instance
<4> Save the configuration

TIP: By default the Minion generates a unique id.
     If you want to provide a human readable Minion identifier yourself with `config:property-set id my-minion-name`

.Configure the credentials for the REST endpoint and exit Karaf shell
[source,karaf]
----
opennms:scv-set opennms.http my-minion-user my-minion-password<1>
----
<1> Set the credentials for the REST endpoint created in your {page-component-title} Core instance

NOTE: The credentials are encrypted on disk in `etc/scv.jce`.

.Configure the Kafka endpoints for RPC feature
[source, karaf]
----
config:edit org.opennms.core.ipc.rpc.kafka
config:property-set bootstrap.servers my-kafka-1:9092,my-kafka-2:9092,my-kafka-3:9092<1>
config:update
----

<1> Connect to the following Kafka nodes and adjust the IPs or FQDNs with the Kafka port accordingly.

.Configure the Kafka endpoints for Sink feature
[source, karaf]
----
config:edit org.opennms.core.ipc.sink.kafka
config:property-set bootstrap.servers my-kafka-1:9092,my-kafka-2:9092,my-kafka-3:9092<1>
config:update
----

<1> Connect to the following Kafka nodes and adjust the IPs or FQDNs with the Kafka port accordingly.

NOTE: If you set more than one Kafka node as `bootstrap.servers` the driver will attempt to connect to the first entry.
      If that is successful the whole broker topology will be discovered and will be known by the client.
      The other entries are only used if the connection to the first entry fails.

IMPORTANT: Ensure you use the FQDN or IP for your Kafka nodes as configured as advertised listener.

Exit the Karaf Shell with kbd:[Ctrl+d]

.Restart the Minion to apply the configuration
[source,console]
----
sudo systemctl restart minion
----

.Verify the configuration using the health check in the Karaf Shell
[source, console]
----
ssh -p 8201 admin@localhost
----

.Run the health check command
[source, karaf]
----
opennms:health-check
----

.Verify if all components are configured properly
[source, output]
----
Verifying the health of the container

Connecting to OpenNMS ReST API           [ Success  ]
Verifying installed bundles              [ Success  ]
Connecting to Kafka from RPC             [ Success  ]
Connecting to Kafka from Sink Producer   [ Success  ]

=> Everything is awesome
----
