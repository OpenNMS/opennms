
// Allow GitHub image rendering
:imagesdir: ../../../images
==== Configuration

===== Enabling Timeseries Integration Layer

_{opennms-product-name}_ can be configured to use the Timeseries Integration Layer by setting the following property in `${OPENNMS_HOME}/etc/opennms.properties`:

[source]
----
org.opennms.timeseries.strategy=integration
----

After activating the _Timeseries Integration Layer_, you need to start an actual implementation.
Do this via Karaf.
Here is an example of how to activate the _in memory timeseries_ plugin:

----
clone & build:
git clone git@github.com:opennms-forge/timeseries-integration-inmemory.git
mvn install

in Karaf shell:
bundle:install -s mvn:org.opennms.plugins.timeseries.inmemory/timeseries-inmemory-plugin/1.0.0-SNAPSHOT

----

For specific instructions, check your plugin description.

We also highly recommend that you reference resources stored in the _Timeseries Integration Layer_ by their foreign source and foreign ID, as opposed to their database ID.
To this end, set the following property in the same file:

[source]
----
org.opennms.rrd.storeByForeignSource=true
----

With these set, _{opennms-product-name}_ will begin persisting metrics using the _Timeseries Integration Layer_ when restarted.

Additional configuration options are presented in the next section.

===== Configuration Reference

The following properties, found in `${OPENNMS_HOME}/etc/opennms.properties`, can be used to configure and tune the _Timeseries Integration Layer_.

[[ga-opennms-operation-newts-properties-general]]
====== General
[options="header, autowidth"]
|===
| Name                                            | Default              | Description
| `org.opennms.timeseries.max_batch_size`       | `16`                 | Maximum number of records to insert in a single transaction. Limited by the size of the Cassandra cluster's batch_size_fail_threshold_in_kb property.
| `org.opennms.timeseries.ring_buffer_size`     | `8192`               | Maximum number of records that can be held in the ring buffer. Must be a power of two.
| `org.opennms.timeseries.config.writer_threads`       | `16`                 | Number of threads used to pull samples from the ring buffer and insert them into Newts.
| `org.opennms.timeseries.query.minimum_step`          | `300000`             | Minimum step size in milliseconds. Used to prevent large queries.
| `org.opennms.timeseries.query.interval_divider`      | `2`                  | If no interval is specified in the query, the step will be divided into this many intervals when aggregating values.
| `org.opennms.timeseries.query.heartbeat`             | `450000`             | Duration in milliseconds. Used when no heartbeat is specified. Should generally be 1.5x your largest collection interval.
| `org.opennms.timeseries.query.parallelism`           | Number of cores      | Maximum number of threads that can be used to compute aggregates. Defaults to the number of available cores.
| `org.opennms.timeseries.config.cache.strategy`       | See below           | Canonical name of the class used for resource level caching. See the table bellow for all of the available options.
| `org.opennms.timeseries.config.cache.max_entries`    | `8192`               | Maximum number of records to keep in the cache when using an in-memory caching strategy.
|===

Available caching strategies include:

[options="header, autowidth, footer"]
|===
| Name                        | Class                                                                   | Default
| In-Memory Cache             | `org.opennms.netmgt.timeseries.support.GuavaSearchableResourceMetadataCache` | Y
|===

===== Recommendations

You will likely want to change the values of `cache.max_entries` and the `ring_buffer_size` to suit your installation.

Meta-data related to resources are cached in order to avoid writing redundant records.
If you are collecting data from a large number of resources, you should increase the `cache.max_entries` to reflect the number of resources you are collecting from, with a suitable buffer.

The samples gathered by the collectors are temporarily stored in a ring buffer before they are persisted to the _Timeseries Integration Layer_.
The value of the `ring_buffer_size` should be increased if you expect large peaks of collectors returning at once or latency in persisting these.
However, note that the memory used by the ring buffer is reserved, and larger values may require an increased heap size.
